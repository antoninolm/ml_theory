{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e7c951",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 28px;\"><b>Evaluation Metrics</b></p>\n",
    "\n",
    "When we build a machine learning model to classify data, it’s not enough to just make predictions — we need to understand **how well the model performs**.  \n",
    "Different evaluation metrics give us different perspectives on the model’s strengths and weaknesses. By using a combination of these measures, we can make informed decisions about whether the model is suitable for our problem or needs further improvement."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "aebcc4fe",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "When building a machine learning model that makes predictions, an essential step is evaluating its performance. To do this, we often use a **confusion matrix**, which summarizes how well the model’s predictions match the actual outcomes.\n",
    "\n",
    "Suppose we are creating a classifier to detect spam emails. After passing the evaluation set through the model, we compare predicted labels with the true labels. Each prediction falls into one of four categories:\n",
    "\n",
    "- **True Positive (TP):** Predicted spam, and it was actually spam  \n",
    "- **True Negative (TN):** Predicted not spam, and it was actually not spam  \n",
    "- **False Positive (FP):** Predicted spam, but it was not spam  \n",
    "- **False Negative (FN):** Predicted not spam, but it was spam  \n",
    "\n",
    "These outcomes can be visualized in a confusion matrix, where rows represent the actual labels and columns represent the predicted labels:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "In practice, we calculate these values from the evaluation data to construct the confusion matrix, which then serves as the foundation for many other performance metrics in classification tasks.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e32036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 3\n",
      "True Negatives: 0\n",
      "False Positives: 3\n",
      "False Negatives: 4\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0 3]\n",
      " [4 3]]\n"
     ]
    }
   ],
   "source": [
    "# Import the confusion_matrix function from scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Checkpoint 1:\n",
    "# We are given two ordered lists:\n",
    "#   - actual: the true labels of the dataset (1 = spam, 0 = not spam)\n",
    "#   - predicted: the classifications returned by the model\n",
    "# We need to create four variables to store the results,\n",
    "# initialized to zero.\n",
    "# ----------------------------------------------------------\n",
    "actual = [1, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n",
    "predicted = [0, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
    "\n",
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Checkpoint 2 & 3:\n",
    "# Loop through each prediction and compare with the actual label.\n",
    "# - True Positive (TP): actual[i] == 1 and predicted[i] == 1\n",
    "# - True Negative (TN): actual[i] == 0 and predicted[i] == 0\n",
    "# - False Positive (FP): actual[i] == 0 and predicted[i] == 1\n",
    "# - False Negative (FN): actual[i] == 1 and predicted[i] == 0\n",
    "# ----------------------------------------------------------\n",
    "for i in range(len(actual)):\n",
    "    if actual[i] == 1 and actual[i] == predicted[i]:\n",
    "        true_positives += 1\n",
    "    elif actual[i] == 0 and predicted[i] == 0:\n",
    "        true_negatives += 1\n",
    "    elif predicted[i] == 1 and actual[i] == 0:\n",
    "        false_positives += 1\n",
    "    elif actual[i] == 1 and predicted[i] == 0:\n",
    "        false_negatives += 1\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Checkpoint 4:\n",
    "# Print the counts of true positives, true negatives,\n",
    "# false positives, and false negatives.\n",
    "# ----------------------------------------------------------\n",
    "print(\"True Positives:\", true_positives)\n",
    "print(\"True Negatives:\", true_negatives)\n",
    "print(\"False Positives:\", false_positives)\n",
    "print(\"False Negatives:\", false_negatives)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Checkpoint 5 & 6:\n",
    "# Use scikit-learn's confusion_matrix function to compute\n",
    "# the matrix directly, and print the result.\n",
    "# ----------------------------------------------------------\n",
    "conf_matrix = confusion_matrix(actual, predicted)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAABhCAYAAACOCji+AAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAACrGSURBVHhe7d13VFRX1wfgHwEC1iAd7A0VgRlQFAXBiAyIUcHe3hgVS+zGloglxZ5iLNEYY9Q3amK+WKLGhkZAsZEoSAAVxQrSEaSMTNnfHzJX7qVoMorl3c9ariXn3Hpmc2ZzzrkzoEqER5wh2/quFB5xRlpFKpWa3hs1nQYMGkfFxUoqLlbSiJHTqUnzTrThu20UEXmWPl30NVnZymjJ0jWk1WqJiOi/P/5KVrYymjZ9IUVEnqVt23eTi9yPuiuGUHZOLhERzV/wOVnZyujrVd/T7weP06ChE6iTZx+ysZfT4SPhREQUExNPDRq7Cz/rpKamk9zNnwICh1NYWCTt/e0IKQKGkqWNC/UKGkkFBYVPfR1EROejY8iuvhtZWDvTocMnypypPOk17dsfRrb1XSl03nI6FXWeJk+dTy0cvCghMUm6KxER5eU9oOB+IdSgsTt9s24LhR07KbShhbWz6F737Q8jG3s5TZ46n44cDReuP7hfCOXlPSCq4HoqKpP+rLNq9SaSuSooLS2DqMy1ucj9aNv23XTkaDhNnjqfbOzltG9/mLDfvv1hZGUro0FDJ9DvB4/T7j2HyKfbALKwdha1v9Sq1ZuE1zwi8iwtWryK6jdqL9y3Vqul1Wt+ILsG7Wj1mh/o+B9RNGjoBPLw7E0ZGVmUl/eAFAFDqZWjDyUl3ZAenjHGWDWAtICISKvV0uwPFwsddkX+79cD1KCxO8XExBMRUWFhEX3y2UrhjaCtSzfa+P0OKilRCftotVratz+M2nUIJAtrZ7Kt70rTpi+k9PRMYZuc3PsUMnYWWVg7U/1G7Wn55+vo7LkLT/VGSEQUFRVNHp69ycLamZq17Ewbv99Ba9ZuFr2hPc11EBEVFBRSr6CRVbaDjvSatFot7d57iNq6dCMLa2dyaONNu/ceEpKriuTk3qcPZn5KtvVdycLamXr2HiG0c9l7rej654Yuo/z8R8kEEdGt2yn0UegyiotLrLRMes060oSCiCg9PZOmTFsgJDieXYIo8uQ50f1otVoKO3aSOnbuJbT/N+u2UMiYWVUmFIWFRTQ3dJlw7N5Bo+h8dAy5ufcQrq2kREXfrNtCzVp2JgtrZ/Lw7E1RUdFEpa/ToCHvk4dnb0pJSZMcnTHGWHUwICICq5BS+RDvvjcVTZs2wrIlH8HAwEC6CWOMMcYAvCEtYI/duHkHl+IuQ+Hnw8kEY4wxVgVOKKoQFRWNevXegotza2kVY4wxxsrghKIShYVF2HcgDF19OsHKykJazRhjjLEyeA0FY4wxxvTGIxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSMMcYY0xsnFIwxxhjTGycUjDHGGNMbJxSsWh07fgqWNi5o1LQjZK4KtHXxhaWNC6zt5HCWd4fMVYFGTTuiYZMOiI1NkO7+3G3Z+otwTZY2Lmjr4guZqwIyVwVatPJC6LzlePCgQLrbv1JYWIT+A8fhnT7vIT+/6mOq1RrMnL0Iru0CcOduqrT6lRAffwVNmneCXQM3yFwVcJZ3h7WdXNTOLVp5wdLGBUeORkh3f+4SEpPg3bUf7Bq4wdLGBTNnL4JarRHq5y/4HI2adhTid/6Cz0X7V7fXISbY64UTClatNBoNBg/qjauJkYi9eBR/hP2MBvXt4OHhhrNR+xB78SiuJkaiu68X0tIzpbs/d++NGIjzZ/ajc+f2aFDfDn+E/YzYi0cRe/Eoos/9jviEJIwYOf2JCcDTeFhSgszMbDzIL4BaoxbKY2MTsGXrL6JtNRo1MjKyUKxU4qGyRFT3ojx8+BDHjp0UvelWRa3WoFOndkj4+wRiLx7F2ah98PBwE7XzlYRITJ0yGleuXJfu/tw5tmmJyPBd+PTjmbC0NMd/f/wVx46fFOo/+3QWYi4cQb++gfjr/EF89uks0f7P06sSE+x/GycUrFqlpWUgwL8rTE1NpFUCU1MT9OsbKC1+4eqZvYXgIH9EnjyHPXsPSav/MfN6Zjh6eDuOHt4O83pmQnnyjdsoKCgSbWtiYoJNG7/AhehDaNGiiajuRVGrNTgfHYOHDx9Kqyp0Py8fnT3aoZ7ZW9IqgaHhG3inpy9q164lrao2xsZGWLr4Q1hZWWDR4lXIysoR6kzefBONG9VHzZo1RPs8b69KTLD/bZxQsGpFRGjYwF5aXE6dOrVx586/G8YlImg0WmnxM2Fraw0AOB8dI636V0xMTGBi8ji5unHjNpYuXwuttvz1GxsbVfsb2bOkVD6Eg0MzaXE5tWrVxN2Ue9Lip/a0IyZVada0ET5eMB2Xr1zHyq83goikm1Sb1zkm2OuFEwpWrQYO6AVHRwdpcTk+3h4IGT1EmLdu5eiDCZNC0ahpR/TsNQIJiUkICBwOSxsXTJwcCgCIiDyLFq28YGUrEw1VFxUVI3TecjjJfOEk88WMWZ/96ymL68m3AAAd3OVC2ZWr19EneLSw1mLd+q1QqR5NYahUaqxbvxXtOgRC5qpAj57/wYdzlwKlc/J2Ddwgd/NHenomEhKT8J8RU3Hz5l188dUGyFwVGDN2NoqKirFl6y+itSVFRcUYM3a2MN8/KmQGioqKsemHn4U5ft0QeUZGFkLGzoKT7NE6hc+//Fa4vtOn/0R3/yGQuSrg020A+vYfg/TnNNXU1ccDXX08pMXlOLRshgXzpiEi8ixaOfrA0sYFU6cvhGu7ADR38ER4xJlybZeVlSPEw9TpC4RjERH2/HYYbu0D4CzvjoDA4YhPuCo6X2WC+gSgT28FNm76CRGRZ6XVgqriq+zrrzv/uPc/RFffgfjks5XC9Xl5Bwvxs+KL9VAqH436vIiYuH79lhDPHp690Sd49AtZz8ReQcTYC5SWlkEyVwX1ChpJBQWF0moiItp/IIwsrJ1p5dcbadv23SRzVdC1azepoKCQegWNpAmT5grb3rx5h9o4vU2Hj4QTEVFxsZKGDJtEk6bMo5ISFRUUFNKgoRNobugy0mq1Zc7ymO64MlcFpaVlCOXJybfI3aMnBfcLoby8B0RE9NeFOHJz70F//nWJqPR8EyeH0rQPPqaSEhWdijpPIWNmUUmJioiIjh0/RdM++Fg45qrVm0Tn0Z171epNwjY6h4+EU4PG7hQTEy+U7d5ziFo4eFFCYhJR6f5jx8+h5ORbRESUmZlNnl2CaOXXG0mr1VJ6eiZ18elLm7fspOycXBowaBxdv/5o2/T0TBo0dILonqtSUFBIi5esrvR1e5LK2rmslJQ0cpL5Us/eI+ivC3Ekc1XQ9h17iCpoO5VKTe+Nmi6Kh81bdlL7jj3p1u0U0mq1tPH7HeTdtR9lZmYL20ht3rJTaOPEy9fIoXUX6q4YQtk5ueXu+UnxtXvPIWrj9LbQxhu/30GKgKH04/ZdtGjxKsrNzSM//yFC/Gfn5FJ3xRBavmKdcD3VGRNKpZLGjJtNJ0+dE/YdM2626PiMVYZHKNhLz9jYGKamJvDx8cCwocGIuXAEzZs3lm4GlK6/eNPYWPj53PmLOBEehf79esLY2Ai1atVE/76BOHw0QjQ3XpHUe+kYMXI6egePgp//UAwZPgljRg/Fjm1rUbdubajVGqz/9r9wcW4NmYsjUHr+4cP64cCBY4iJjUfspUTExiXg1q27AACZSxs0b/b42lu1ai78/0lsbaxEay0AwKOjG2rXroWoqGgAQEpqGpo3a4wmTRoCAH4/eBzp6VkIDOwGAwMDWFtbwl/hg337w5CcfBuX4i4jJjYeGo0W1taW8OrsDkNDQ9E5XiRDwzdg+IYhfLt5wc3VCTEXjmDokCDpZgAAIyND0fB/ds59bPz+J3T39UKjhvYwMDCAX/cuyMrORcxT/sXdulVzfPThJFyM+RsbNmwrN+3wpPiKiDiLZk0bwtraAgDQsKE9EhKT4Ny2NULnToGZWV18vfITLFvyEWrVqgnzemZwcGiKU6ejUVgoXjNRkWcdE+npWbgYE4/oPy9BpVKjVq2aUPh5w/jNx79TjFWGEwr2SrC0MIe9nY2ozMDAAEZPePOLjU2ASqXGwk++Qu/gUegdPAobvtsOO1srGBgYSDcXsbezwdbNK7Fvzw8IO7IDZ6P2YUzIUGFBaXZ2DqKjY1GzZg0YGT2+jhqmJlA+fIjoP2PRxbMDsrNz4eHZG3YN3PBR6DIMHPBOmbPox9bWCgqFN/YdCENhYRGio2PRrp2LcG/no2OQl/8AU6YuEO7/6LGTsDCvhyaNG8CpbSuMHT8HNvZydPUdCDdXJ1hamktPg2vXbmLI8EnCMXoHj8KgIe9j+097MWjI+6LykaM/wL17GdJD6MWxTUtpEYyMjaRFInfvpOL2nRQcPPiHcG0TJ4fC1NQExk/Yt6zBg/pA4eeDdd/+Fxcu/i2qe1J8BQX54+7dNGRkZIOIcOFCHBzbtETTpo2EYzRr2giJiUnw7zEMnb2C9H5kVp+YMDN7Cz7eHli8ZDXsGrjBtV0ADI0M0aZ1C+lpGCuHEwr2yqpZswbs7B4tkqxKjRqmWPXVx9i35wchOTiwb2uFb5zPklqlhrNza5w+uRcfzpkIZ6fW+G3fUYSMm/3Evz6Tk28DAE5FncftKhanGhgYQOHng0uXEvHXhTgkJFyFXN5WtE3ZxGjfnh8Q8cf/YeN3K2BpaY5t/12NDeuXoUfA20hOvoVBQydUOF/eokUT/LRtrXCMfXt+wM6f1mPYkCDs/Gm9qHzzpq+e6nXRV9mRnqqMHjVYuLYD+7bir/MH4eP95LUcOqamJlgwfxpq1jDF/AWfI/d+nqi+qviyt7eBp2d7TJvxMd7uPgjJN25j86avULdubQBAfn4Bhg6fhM1bf8F3G1bg9Km98Ff4iI6vUx0xUbdubSxfOhc/bVuLfn0DUaxUYuy4Ofj94HHR/oxVhBMK9lpRKh+iRKUSfu7UqR0MDQ2RlZ0r2i4+4aqw8O3fMjOri9ZtWiA7577o0cn7eflQq9WQyRzx7XfbcDEmHjM/GIejh3fg0O8/4tbNu7h27aboWFIq9aN7uHbtJnJz7kurReTytqhvb4v1G36Evb0NLMwfD4F39+2CwsIi5OQ+fhNUqzWIT7iKS5cSsWjxKvQN7oEft67C37HHIZM5VrkA8WWmVmtQVFQs/Ny0aSM4tmmJlNQ00VMa9+5lVDmCkp9fUO4zUHRTHwmJSbhyNVkof1J83bhxB16eHbBvzw8IP/4LNm5YAXv7xyNtkSfP4nx0DD77ZCYaN6ovOkZc3GX8/fdl4efqiIl79zIwfcbH6Ny5PTasX4a4mGMYPKg3Dh0+IWzLWGU4oWCvNGMjYxQVFUOt1oCIsG9/GDIysoRPs5TL2iI4KABr1m4W/rK8fScV23fskRzpnzMxMcHsme8jKekG/o5/9OSASqXGr7t+x+BBfdC5U3uUPCzBdxu3C6v+65m9hebNG6NBw4ofnTUxMYGFuRmKioqhUqmRmpoOs3qVf24DAFiYmyGwx9uICD+DDh1cRXW+3bzg7NwaGzZsExKo2EsJOHDgGLRaLQ4dCcfFmHig9C9tG2tLyGSP1oO87AwNDaFSq4X7uhSXiMiT54R4qFu3NiZNHIn9B44h+s9YoPT12bBxG/LyH0iO9phGq4WqTFKqo5v6KOtJ8WVoaIio09FITU0XnkYp+0hznTq1odFokJmZDQC4czdVuNaU1DSkpKZXa0wYGABnz13AHydOA6XrUiwtzUVPNTFWKekqTcaqQ3jEGXKR+5FDG2+ysHYmC2tncnTuRi5yPwqPOCNsN2/+CmrYpANZWDuTQxtvmjd/heg4cXGJ1NkriBzaeJO7R0/6dNHX1NalG9nWdxW2LS5W0pq1m8lF7kdu7j1o4uRQSk/PFB1HZ/OWneQk8yUrW5lwTdJzSp09d4F69npXOP7yz9dRcbGSiIjWb/iRFi9ZTQGBw8lF7ke+isEUFRVNJLm3Tp59KD7hKlHpPXXs3Itkrgra8N020mq1tHnLTmru4Cm0Q9k2IiI6Hx1DffuPEZ4+KSs//wHNDV1GbZzepnYdAmnhJ19SYWERxcTE07QPPqbxEz4iuZs/ubn3oG/WbRGeSHkS6RMPTys+4Sp18elLjs7dhNfeoY03ucj9aPOWncJ24RFnhPho2KQD9ez1rujpjLy8BzR2/Bxq1rIzyd38adKUeTRw8HiysHYm/x7DKDMzm7RaLUWePEc+3QaQk8yX3unzntD+UvEJV6mTZx+ysHYmK1sZBQQOL/c0SOLlazR6zEzRPVcVX3dT7pGbew/hPnX/xo6fQ3l5D6ikREXfrNtCLRy8SO7mT4OHTaQDvx+jNk5v08DB44UnWKorJtLSMmj8hI9ozkdLyM29B7nI/Sh03nIqLCySHoKxcgzoRX5iC2PPGBFBqyUYGvLg2/NWWFiEVas3YeqU0ahVq6a0+oVQqzWiBbIvUmFhEUaPnYWB/d9BcFCAsCjy1u0UjB03G0OHBGHEuwOkuzH2yuJel71WDAwMOJmoJiYmJhg4oNdL9UmNL0syAQAajRYFBYXSYtStWxvGbxqjbt060irGXmk8QsEYY89Jamo6Pv9iPU5GRUNV8mhdRsOGdpg6eTS6dfPi5Je9VjihYIwxxpjeOD1mjDHGmN44oWCMMcaY3iqd8ugdPEpaJGJhboYliz6slk/EY4wxxtjLrdKE4lno03e0tIgxxhhjr4Hfdm8S/fxcEwrGGGOM/W+oNKHgKQ/GGGOMPa1KEwrGGGOMsafFT3kwxhhjTG/PNaE4dvwULG1c0KhpR8hcFWjr4gtLGxdY28nhLO8OmasCjZp2RMMmHRAbmyDd/bnbsvUX4ZosbVzQ1sUXMlcFZK4KtGjlhdB5y4VvrdSXWq3BzNmL4NouAHfupkqryzl8JBx2Ddyw97cj0qpXQnz8FTRp3gl2Ddwgc1XAWd4d1nZyUTu3aOUFSxsXHDkaId39uUtITIJ3136wa+AGSxsXzJy9CGq1Rqifv+BzNGraUYjf+Qs+F+3/IrzqMSFt8xatvITfN5mrQig/dvyUdNcKzV/wOewauEHu5o90ydeN66s6+4bCwiL0HzgO7/R5T/hW2qq86nFQVdvqytt1CBS+gfVJqisOrO3kOHwkXKjLyspBj57/Efq1Vo4+iIg8K9q/uv3T95lnrswXhT1zh4+E08TJocI3L6alZZDMVUG9gkYK39ZXXKyk90ZNp8NHwiV7V4+CgkLqFTSSZK4K4Zv9iIhycu9Tn+DRFNwvpMJv6/unlEol/WfEVGrl6ENJSTeE8sq+sfHH7bvI0saFfty+S1T+IoWFRZa7zsrExMTT4GETKSf3PlEl7axWa+jTRV/TqtWbJHtXn+82bqdWjj5kZSujQ4dPiOqyc3Jp7Pg5lJGRJSp/3l7XmNBZtXoTWVg7l/udLy5W0sTJofR/vx4QlVdly9Zfyv3uPisVxSw9h74hOyeXvLv2I++u/Sg7J1coj4mJF337qs7rEAeVtS0R0fXrt6hn7xF08+YdUXlVnnccjAqZQfUbtScPz96UkpImqj956hwt+PhL0mq1ovLn7fCR8HK/Q5W9z1SX5zpCkZaWgQD/rjA1NZFWCUxNTdCvb6C0+IWrZ/YWgoP8EXnyHPbsPSSt/sdMTEywaeMXuBB9CC1aNBHKs7JzcefuPdG2ADBsSDBuXDuNYUOCpVUvTPSfsRV+2VFF7uflo7NHO9Qze0taJTA0fAPv9PRF7dq1pFXVxtjYCEsXfwgrKwssWrwKWVk5Qp3Jm2+icaP61f7lV69rTDyJqakJhg/rh9zcPGlVpWxtq39R+LPuG8zrmeHo4e04eng7zOuZCeXJN26joKBItC3+B+KgWbNGUHT3xv37+dKqSj3vOGjerDE+WTgDSUk38M26LSi79LBO7dpo2qSB8G2y1aWiUf3K3meqy3NNKIgIDRvYS4vLqVOnNu7c+ffDM2WHqp8lXZCej46RVv0rxsZGojcnpfIhVq7ciJTUNNF2KP3WzNq1a1V7kD4rSuVDODg0kxaXU6tWTdxNKf/m+bQ0Gq3ol/vfaNa0ET5eMB2Xr1zHyq836n08fbzOMVGVpcvWIj09E40a2iMjI0ta/dJ51n2DiYkJTEwe/+F148ZtLF2+FlqtVrQdXuM4SE/PxNJla4HSpCLtGU9f6Cs4OAB9eiuwcdNPL3xq43x0DDZs3CYtBip4n6lOzzWhGDigFxwdHaTF5fh4eyBk9BBh3rqVow8mTApFo6Yd0bPXCKSnZ5abJ8vKykFA4HBY2rhg6vQFwrGICHt+Owy39gFwlndHQOBwxCdcFZ3vaV1PvgUA6OAuF8oePChA6LzlkLkq4CTzRcjYWaIO8PTpP9Hdfwhkrgr4dBuAvv3HID09E1u2/iJaL1JUVIzJU+Zj995DOHv2Ajw8e8O7az8kJCYhITEJHTq9A0sbF6xe8wMgmdP38x+KrKwcnAg/DWs7OewauAlz/EVFxQidtxxOMl84yXwxY9Znwrzs9eu30Cd4NGSuCnh49kaf4NEVZrnPQlcfD3T18ZAWl+PQshkWzJuGiMizaOXoU/p6LoRruwA0d/BEeMSZCtsuZOwsWNvJEdw/BEVFxcLxTp/+E119B8JJ5gsv72CcCD8tOl9lgvo8XWdRVftC8vq7tQ/ApCnz0G/AWPTo+R/k5N7H9eu30G/AWLi2C4CTzBfD352C26XJ9OseE5XJyspB4uVrAAB7exuEzp0ClF5bZW1Vmaru52XtG6R9W0JiEv4zYipu3ryLL77aAJmrAmPGzkZRUfFrHQeJl68hKzsXAPBOz+7wV/gAzyEOqmqHqpi8+SbmzZ0CKysLzJu/QjSaKZWRkYWQsbPgJHu0PuTzL7+FSqUGSs8/b/4KIU4GD5uIUSEz0K5DIHb8tBcqlRrr1m9FJ68+Qj/y47Zd0GgeJZcRkWcxcvQM5OU9wMTJoZC5KoTXuKK+cszY2cL6pFEhM1BUVIxNP/wMy9L1YVu2/vLEa64sdsuRzoE8TxWtoZDafyCMLKydaeXXG2nb9t0kc1XQtWs3iUrnXsvOk6lUanpv1HSaMGmusP/mLTupfceedOt2Cmm1Wtr4/Q7y7tqPMjOzhW3KqmwuLzn5Frl79BTNk+blPaDgfiG08uuNpNVqSavV0q7dB8mzSxDdvpNC2Tm5NGDQOLp+/RYREaWnZ9KgoROE4x4+Ek4NGrtTTEy8cJ5VqzdV2B66tiq7vuB8dAw1buZBx46fEspmzv6Mzpz5i6h0DnrIsEk0aco8KilRUUFBIQ0aOoHmhi6j4uJiGjNuNp08dY6o9L7HjJstupYnWbJ0zb+eo6ysnctKSUkjJ5kv9ew9gv66EEcyVwVt37GHqJK2W7R4lajtToSfJofWXejPvy4REdGx46fIRe5HiZevCftIbd6yUzhm4uVr5NC6C3VXDKHsnNxyaxmqal+tVks3b90lJ5kv7fhpLxERJSQmkcxVQb/u+p1Cxs6izMxsWrb8G+E+tFotLVm6hhQBQ0Vz8a97TOjWUHTy7EP+PYaRla2swrh4mrY6fCRc2FepVFZ5Py9z3yDt23Tnrmh90esQB7r7s7KVkX+PYdTJsw9ZWDuL+nKdZxkHVbVDZWsgpP3A5i07ycLamZYsXUNarbbcWpfMzGzy7BIkxEJ6eiZ18ekrbLN8xTrq6juAsnNySavV0uwPF1PI2Fn05crvaNv23XTrdgo5OncT2iI5+RY5yXxp955Dwjl0MSBdQ0GV9JW79xyiFg5elJCYRFR6T2PHz6Hk5EfxWNU1Pyl2y3quIxT/hrGxMUxNTeDj44FhQ4MRc+EImjdvLN0MAGBkZCga2snOuY+N3/+E7r5eaNTQHgYGBvDr3gVZ2bmIeUK2nXovHSNGTkfv4FHw8x+KIcMnYczoodixbS3q1q0NADj+xylcuZqM4KAAGBgYwMDAAN3e9oRpDVP89NNvuJeajktxlxETGw+NRgtra0t4dXaHoaEhAMDWxko0R1qV2rVroVHj+qIyxzYt4eLSBkfDIkBEyM65jzeNjSGXtwUAnDt/ESfCo9C/X08YGxuhVq2a6N83EIePRuDmzbu4GBOP6D8vQaVSo1atmlD4ecP4TWPROV4kQ8M3YPiGIXy7ecHN1QkxF45g6JAg6WaCOnUevS4A8PDhQ3z73Ta4ujnDqe2jUbF2bs6wsrbAHyeiyuxVudatmuOjDyfhYszf2LBhW7nh5qraNysrB0lJN5CX9wCtWzcHAJjXe7R+JCUlDRs3rIClpTlCQobi5x3fwNHRAQYGBnBzc0ZCYhJu3LgtOldFXreYWLhgOg4f3IbLCeGQyRyl1f+4rfLzCyq9n5e9b2jV6lHMPI3XKQ7s7WywdfNKnD61F3t3fw9TU1PpJs80Dqpqh6pGHMoaPKgPFH4+WLN2M86duyitxu8HjyM9PQuBgd1gYGAAa2tL+Ct8sG9/GLKycnD23AU4tGyGemZvwcDAAPXtbREdHYthQ4IwbGgwGjaww+ZNX+LDORMBANbWlmjatBGOHT8pPVWFKnqf8ejohtq1ayEqKhoAkJKahubNGqNJk4bAE645Ofl2lbFblpG04GVgaWEOezsbaTGMjKu+3Lt3UnH7TgoOHvxDGMrUajQwNTWB8RP21QW2jY2VtEpw7PhJGBsZiRaZ6uarzp67gFEjB8GpbSuMHT8HY8fPgZNTayz5bDYsLc1Fx/m3atWqid7v+OGbdVsxbUoIriYlw8GhmXA9sbEJUKnUWPjJV0JHV1ykhJ2tFczM3oKPtwcWL1mNxUtWo2EDeyxYMA1tWreQnAXIyb2POXOWID1TPJednHwLEZFn8abJm0KZqcmbWDh/Otq2bSXaVh+ObVpKi2BoaFhhAOvcv5+Py4nXUFBYiAGD3wdKh7jz8x+gZo3ynVRlBg/qg6NhJ7Hu2/+ic+f2orqq2tfAwABymSMaNbTH5cvX4Sp3wo0bd1CsVKJTp3bCMczrvQVTU1NMmDgXF2L+hqGhfjn96xAT5vXM0LqCN9R/2lb16plVej+XLiVy3/CSx0HLFk1haVFPWvxM4+DYsZOVtsPTrkkxNTXBgvnT8NdfsVi0dDVmz3zU3+icj45BXv4DTJm6QGiPvLwHcGjRFDVr1kDvXn7YtmMPcu/noU7t2oi9lAB3dxksLB7FgoGBAdq0boEft+3Czv87ALVKjVu376JhAzvRef4JW1srKBTe2HcgDEMG90F0dCzatXMR7rmqa27SuMHTx650yOJ50g3TVDScq1N26EqqoroJk+YKQ0MxMfHUoLF7hcOElalsWLMiEybNLbedbn/dPRUXK+nXXb/T8HenUMMmHURDTzEx8eQi9ys35eHm3oMyMrLo1u0U0TBdRUOeCYlJ1MLBi37d9TstX7GOrly9LtStWr2p3FBXWWq1ho4ejaCx4+dQK0cfsrRxof0HwqSbVeqfDmuW9TTtXNUwXmVtp2t33b4VDZlWpeyUh45u6qOLT1+aOfszIVaf1L5KpZI+nLuURo+ZST7dBpAiYChFnjwnDKVqtVpaveYHau7gSWHHTpJaralwePJ1jwndlEdFr7PO07aVtE+o7H5e9r5Beh+6fadOW0hU+mjirdspojrpvbxKcfC0bfus4+BJ7VCRgkoe49ZNfQweNpE2/fCzUF5RLJQVHnGGJk2ZR37+Q6iLT1+aG7qM8vMfT9/cvpNC7h49aez4OcLUa6+gkaK+TdfffbN+K1HpUoH79/OJKukrqXQKuHEzD4qIPEtzQ5dRVvbjR5SfdM1VxW5ZVad6Lzm1WiNakNe0aSM4tmmJlNQ00Ur9e/cycO9ehvDzv9XBXY7CwiLk5T8QypQPS5CdlYu2jg64efMOFi1ehb7BPfDj1lX4O/Y4ZDLHKhf5AYBGrYFWq0Vuzn1cu3ZTWi3SrGlDtGvvgs1bdqKwqBjNmj6eDurUqR0MDQ2FhU068QlXcffuPUyf8TE6d26PDeuXIS7mGAYP6o1Dh0+Itn2VlP1gIQsLc7i7y5CZmQ2l8qFQnns/r9KhUZQOj0pXk+umPhISk3DlarJQXlX7KpUPhcfc1n+zFOHHf8GRQ9vRxauD8FfAvXsZ+O777Zg44T109/US/aV1Py8fB34/Jvz8vx4T/6StdDIzsyu9n1e1b1CpVQCAa9duIjfnvrRahOPgkarioKp2KNtvSKWkppV7LFY39REWFimq6+7bBYWFRcgp8/izWq1BfMJVqNUaXL5yHUMG9cHRwzsQGb4LixfNEU3f/rrrIIqLlVg4f3q5qYtTUedFC1LVpYsm4+IuQ6lUltmyPLm8Lerb22L9hh9hb28DC/PHx67qmi9dSnzq2H2lEgpDQ0Oo1Grhhb8Ul4jIk+dQVFQMtVqDunVrY9LEkdh/4Bii/4wFAKhUamzYuE30i/5vBQf1gLNzaxw8+IfQKUWePAsDA2DC++9Crdbg0JFwXIyJBwDUqGEKG2vLCueHdeztbVCiUkGpfIi09Ey8ZVZXuomIiYkJ+vcNxNlzFyGXOcLI6PE0gFzWFsFBAVizdjNy7z8KjNt3UrF9xx5otVqcPXcBf5x49NSDkZEhLC3NRavUX2ZGRoZQazQoLn3t79xNxW/7j6KoqBgqlRpGRoZ4f/y7+Dv+Kg4dOQEiAhHhp59/w63bKdLDCTRaLVSqR512WbrOoqyq2hcA3njjDVy/fhOXL19Denom0tMz8fDh407KxNQEdevUwd2796DRaKFSqYVP3lMqHyIu7jLAMQH8g7ZKS3ucDFR1P69a32BiYgILczMhvlNT02FWuianMhwHj1R1P1W1Q2WICCqVWnjKQkc39VH2jRkAfLt5wdm5NTZs2Ca8V8VeSsCBA8dgaPgGNBoNTp2OFvqInNz7oiTXvN5bKCoqRk7Oo6TnytVkxMdfAcokliYmJrC0MseDBwUoLCxCsfIhatSo+lFRC3MzBPZ4GxHhZ9Chg6uorqpr1mq1Tx+70iGL5yE84gy5yP3IoY03WVg7k4W1Mzk6dyMXuR+FR5wRtps3fwU1bNKBLKydyaGNN82bv0J0nLy8BzR2/Bxq1rIzyd38adKUeTRw8HiysHYm/x7DKDMzm7RaLUWePEc+3QaQk8yX3unzHkVFRYuOo7N5y05ykvmSla1MuCbpOaXS0zNp2vSF5CL3Ixe5H/1nxFRhKDImJp6mffAxjZ/wEcnd/MnNvQd9s24LlZSoaPOWndTcwVO4N9195+U9oJAxs8ihjTeNCplBeXkPKD7hqrDquWGTDuWu6eatuxT4zrt089ZdUTmVDk2tWbuZXOR+5ObegyZODqX09ExKS8ug8RM+ojkfLSE39x7kIvej0HnLqbCwSHqISv3TYU0ioviEq9TFpy85OncTXnuHNt7kIvcTrYwOjzgjxEfDJh2oZ693RavvS0pU9Omir6lxMw+Su/nTgEHjaNoHH5OFtTO5e/Sk+ISrRER0+co1eqfPe9TWpRv5dBtAe387UuHq7bJtbGUro4DA4eVW+ydevkajx8wUDXVW1r5U+tTR5KnzhfvU/fPw7E1xcYlERBQVFU2dvYLIoY03dfUdQLt2H6SBg8eTzFXx2seELhZs67sK9yGNg7Ke1FZl+wtH526057fDVd7Py9o3lL2PTp59hFiOi0ukjp17kcxVQRu+20Zarfa1iIPNW3aW6w+6+PQV7lvqWcdBZe1QkbL9dkXtrdtmzdrNorL8/Ac0N3QZtXF6m9p1CKSFn3wpnP+vC3HC9er+WdnK6NNFX1NJiYoKC4tobugyatzMg9p1CKTJU+fT9h17qFnLzjR56nyhPwo7dpJaOfpQ+4496eChP4Rrqeh9Rud8dAz17T+mwk94reyaq4pdqVf+20bVao0oE2fPz9JlazFq5KAqF6dVp5fttV+3fisSL1/D58vnCYvhioqK8eXK7xCfcBVbf/hK9OFFr4OXLSbYi8Fx8HRSU9MxKmQGPvl4BjqWjhIQEeLiLmP02Fn4YsU8+Hg/+fN7Xlav1JRHRV6mN5TX3YD+78DcvPwq7BflZXvtCwqKREOXKB2GrlmzBurUrgVDw6qfJngVvWwxwV4MjoOno1KrRev+UOaTT2vWrPHCPuHyWXnlRygYe1kolQ/x47Zd2LL1/1BUVAytVosaNU0xbEgw3hsxQLTwijH2v+nK1ev4bNEqJF6+JiyqdGzrgJkfjIObq9NTP776MuKEgjHGGGN6e+WnPBhjjDH24nFCwRhjjDG9cULBGGOMMb1xQsEYY4wxvXFCwRhjjDG9cULBGGOMMb1xQsEYY4wxvXFCwRhjjDG9cULBGGOMMb1xQsEYY4wxvXFCwRhjjDG9cULBGGOMMb1xQsEYY4wxvVX6baMajUZaxBhjjDFWIR6hYIwxxpjeOKFgjDHGmN44oWCMMcaY3v4fYp7p6aGhWPEAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "bff9b381",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "\n",
    "One way to evaluate the performance of a classification model is by calculating its **accuracy**. Accuracy measures the proportion of correct predictions out of the total predictions made by the model. It is computed using the counts from the confusion matrix:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "In other words, accuracy represents how often the classifier makes the right prediction, whether identifying positive cases correctly or recognizing negatives correctly.  \n",
    "Next, we can calculate the accuracy of our classification algorithm using this formula.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73dcd746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Checkpoint 1:\n",
    "# Calculate the accuracy of the classification algorithm.\n",
    "# Accuracy is defined as:\n",
    "#   (True Positives + True Negatives) /\n",
    "#   (True Positives + True Negatives + False Positives + False Negatives)\n",
    "# Store the result in a variable named `accuracy` and print it.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (\n",
    "    true_positives + true_negatives + false_positives + false_negatives\n",
    ")\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c71769",
   "metadata": {},
   "source": [
    "# Recall\n",
    "\n",
    "While accuracy is a common metric, it can sometimes give a misleading picture of model performance. For example, imagine building a spam classifier for email accounts that almost never receive spam. A model that always predicts \"not spam\" would achieve high accuracy but fail to detect the few spam messages that do exist — missing the actual goal of the classifier.\n",
    "\n",
    "In such cases, **recall** is a more meaningful measure. Recall quantifies the ability of a model to correctly identify positive cases. It is defined as:\n",
    "\n",
    "\\[\n",
    "\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "\\]\n",
    "\n",
    "In other words, recall represents the proportion of actual positive cases that the model successfully classified as positive.  \n",
    "For our spam detection example, recall would be the fraction of spam emails correctly identified out of all spam emails in the dataset. A model that never predicts spam would have a recall of **0**, regardless of its overall accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2dfc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Checkpoint 1:\n",
    "# Calculate the recall of the classification algorithm.\n",
    "# Recall is defined as:\n",
    "#   True Positives /\n",
    "#   (True Positives + False Negatives)\n",
    "# Store the result in a variable named `recall` and print it.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "58b10180",
   "metadata": {},
   "source": [
    "# Precision\n",
    "\n",
    "Just like recall, precision highlights another important aspect of model evaluation. Consider a classifier that always predicts \"spam.\" Such a model would have a recall of 1, since it never misses a spam email, but its accuracy would be low and its usefulness limited because it also misclassifies most non-spam emails as spam.\n",
    "\n",
    "**Precision** measures how reliable the model’s positive predictions are. It is defined as:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "In other words, precision is the proportion of correct positive predictions out of all predictions the model labeled as positive.  \n",
    "For the spam classifier, precision tells us how many of the emails predicted as spam were actually spam. A model that always predicts spam would have high recall but very low precision, since most of its positive predictions would be wrong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc07d998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Checkpoint 1:\n",
    "# Calculate the precision of the classification algorithm.\n",
    "# Precision is defined as:\n",
    "#   True Positives /\n",
    "#   (True Positives + False Positives)\n",
    "# Store the result in a variable named `precision` and print it.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "\n",
    "print(\"Precision:\", precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d07a0",
   "metadata": {},
   "source": [
    "# F1-Score\n",
    "\n",
    "To evaluate a model more comprehensively, we often need to balance both **precision** and **recall**. The **F1-score** combines these two metrics into a single measure using the **harmonic mean**, which penalizes extreme differences between precision and recall.\n",
    "\n",
    "The F1-score is defined as:\n",
    "\n",
    "$$\n",
    "F1 = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}\n",
    "$$\n",
    "\n",
    "We use the harmonic mean rather than the arithmetic mean because it ensures that the F1-score will be low if either precision or recall is close to 0.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- Precision = 0.02, Recall = 1  \n",
    "\n",
    "Arithmetic mean:\n",
    "\n",
    "$$\n",
    "\\frac{1 + 0.02}{2} = 0.51\n",
    "$$\n",
    "\n",
    "Harmonic mean (F1-score):\n",
    "\n",
    "$$\n",
    "\\frac{2 \\times 1 \\times 0.02}{1 + 0.02} = 0.039\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88c7a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.4615384615384615\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Checkpoint 1:\n",
    "# Calculate the F1-score of the classification algorithm.\n",
    "# The F1-score is the harmonic mean of precision and recall:\n",
    "# \n",
    "#   F1 = (2 * Precision * Recall) / (Precision + Recall)\n",
    "#\n",
    "# Store the result in a variable named `f_1` and print it.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "f_1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"F1-score:\", f_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69dda01",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "There is no single metric that works best in all situations. Choosing between **accuracy**, **precision**, **recall**, **F1-score**, or other evaluation metrics depends on the specific classification task and its priorities.\n",
    "\n",
    "For instance, in the spam email example, we would likely prefer a model with high **precision** even if its recall is lower. This is because it is more important to avoid mistakenly classifying an important email as spam than it is to let a few spam messages slip into the inbox.\n",
    "\n",
    "The key is to understand the problem you are trying to solve — that will guide which metric is most meaningful.\n",
    "\n",
    "Libraries like **scikit-learn** provide built-in functions to calculate these metrics, making evaluation more efficient.\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "- Each classification result falls into one of four categories:  \n",
    "  - True Positive (actual = 1, predicted = 1)  \n",
    "  - True Negative (actual = 0, predicted = 0)  \n",
    "  - False Positive (actual = 0, predicted = 1)  \n",
    "  - False Negative (actual = 1, predicted = 0)  \n",
    "  These outcomes are often summarized in a **confusion matrix**.  \n",
    "\n",
    "- **Accuracy**: Proportion of all predictions that were correct.  \n",
    "\n",
    "- **Recall**: Fraction of actual positives correctly identified.  \n",
    "\n",
    "- **Precision**: Fraction of predicted positives that were truly positive.  \n",
    "\n",
    "- **F1-score**: Harmonic mean of precision and recall.  \n",
    "  - This score will be low if either precision or recall is low, reflecting poor balance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48cbdac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3\n",
      "Recall: 0.42857142857142855\n",
      "Precision: 0.5\n",
      "F1-score: 0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Checkpoint 1:\n",
    "# Use scikit-learn's built-in functions to calculate evaluation metrics.\n",
    "# All functions take two parameters:\n",
    "#   - actual: the list of true labels\n",
    "#   - predicted: the list of predicted classifications\n",
    "#\n",
    "# Call accuracy_score() first and print the result.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(actual, predicted))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Checkpoint 2:\n",
    "# Call recall_score(), precision_score(), and f1_score()\n",
    "# with the same parameters (actual, predicted).\n",
    "# Print their results as well.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print(\"Recall:\", recall_score(actual, predicted))\n",
    "print(\"Precision:\", precision_score(actual, predicted))\n",
    "print(\"F1-score:\", f1_score(actual, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec404c5",
   "metadata": {},
   "source": [
    "### Summary of Key Metrics\n",
    "\n",
    "To evaluate classification results, we use four main statistics derived from the confusion matrix:\n",
    "\n",
    "- **Accuracy** → *How often the model is right overall*  \n",
    "  $$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$  \n",
    "\n",
    "- **Recall** → *How many actual positives the model correctly found*  \n",
    "  $$Recall = \\frac{TP}{TP + FN}$$  \n",
    "\n",
    "- **Precision** → *Of the predicted positives, how many were actually positive*  \n",
    "  $$Precision = \\frac{TP}{TP + FP}$$  \n",
    "\n",
    "- **F1-score** → *Balances precision and recall into one number*  \n",
    "  $$F1 = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}$$  \n",
    "\n",
    "---\n",
    "\n",
    "### Easy Way to Remember 🧠\n",
    "\n",
    "- **Accuracy** → “Out of everything, how much did I get right?”  \n",
    "- **Recall** → “Of all the real positives, how many did I catch?” *(think: catching spam emails)*  \n",
    "- **Precision** → “Of all the ones I called positive, how many were truly positive?” *(think: avoiding false alarms)*  \n",
    "- **F1-score** → “How well am I balancing precision and recall together?”  \n",
    "\n",
    "By keeping these short questions in mind, you’ll be able to quickly recall what each metric means and when to use it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
